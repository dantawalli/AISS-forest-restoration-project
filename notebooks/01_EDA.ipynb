{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac856ee91896bb1d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T12:44:24.177881Z",
     "start_time": "2025-11-29T12:44:23.789082Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOADING RAW DATA FROM EXCEL FILE\n",
      "================================================================================\n",
      "\u2705 Excel file loaded: ../data/raw/global_forest_watch_raw_data.xlsx\n",
      "\n",
      "Available sheets: 9\n",
      "\n",
      "Sheet names:\n",
      "  1. Read_Me\n",
      "  2. Country tree cover loss\n",
      "  3. Country primary loss\n",
      "  4. Country drivers\n",
      "  5. Country carbon data\n",
      "  6. Subnational 1 tree cover loss\n",
      "  7. Subnational 1 primary loss\n",
      "  8. Subnational 1 drivers\n",
      "  9. Subnational 1 carbon data\n",
      "\n",
      "\ud83d\udcca Country-level sheets to explore: 4\n",
      "  - Country tree cover loss\n",
      "  - Country primary loss\n",
      "  - Country drivers\n",
      "  - Country carbon data\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "RAW_PATH = \"../data/raw/global_forest_watch_raw_data.xlsx\"\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LOADING RAW DATA FROM EXCEL FILE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "excel_file = pd.ExcelFile(RAW_PATH)\n",
    "print(f\"\u2705 Excel file loaded: {RAW_PATH}\")\n",
    "print(f\"\\nAvailable sheets: {len(excel_file.sheet_names)}\")\n",
    "print(\"\\nSheet names:\")\n",
    "for i, sheet in enumerate(excel_file.sheet_names, 1):\n",
    "    print(f\"  {i}. {sheet}\")\n",
    "\n",
    "country_sheets = [s for s in excel_file.sheet_names if s.startswith('Country')]\n",
    "print(f\"\\n\ud83d\udcca Country-level sheets to explore: {len(country_sheets)}\")\n",
    "for sheet in country_sheets:\n",
    "    print(f\"  - {sheet}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c0e0e9",
   "metadata": {},
   "source": [
    "**Findings:** \n",
    "\n",
    "From loading the Excel file, we discovered:\n",
    "- The file contains **9 total sheets**\n",
    "- **4 country-level sheets** that we'll explore:\n",
    "  1. Country tree cover loss\n",
    "  2. Country primary loss\n",
    "  3. Country drivers\n",
    "  4. Country carbon data\n",
    "- **4 subnational-level sheets** (which we'll skip for now, as we're focusing on country-level analysis)\n",
    "- **1 Read_Me sheet** (documentation)\n",
    "\n",
    "This gives us a clear picture of what data is available and helps us focus our exploration on the four country-level datasets that will be used for our analysis. The presence of both country and subnational data suggests the dataset has multiple levels of granularity, but for this project, we'll concentrate on the country-level aggregation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63583e6b36d97a15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T19:02:11.514834Z",
     "start_time": "2025-11-10T19:02:11.511564Z"
    }
   },
   "outputs": [],
   "source": [
    "---\n",
    "\n",
    "## Part 1: Data Exploration - Raw Data Sheets\n",
    "\n",
    "### Goal: Understand the raw data structure, quality, and characteristics from each Excel sheet\n",
    "\n",
    "We will explore each country-level sheet separately to understand:\n",
    "- Data structure and format\n",
    "- Column names and types\n",
    "- Data quality issues\n",
    "- Relationships between sheets\n",
    "- Patterns that will inform data preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980bcd213043c05b",
   "metadata": {},
   "source": [
    "## Step 2: Exploring Country Tree Cover Loss Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "451d1459c0efd147",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T13:05:08.241524Z",
     "start_time": "2025-11-29T13:05:06.969408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COUNTRY TREE COVER LOSS - RAW DATA\n",
      "================================================================================\n",
      "Shape: 1,328 rows \u00d7 30 columns\n",
      "\n",
      "Column names (30):\n",
      "   1. country\n",
      "   2. threshold\n",
      "   3. area_ha\n",
      "   4. extent_2000_ha\n",
      "   5. extent_2010_ha\n",
      "   6. gain_2000-2012_ha\n",
      "   7. tc_loss_ha_2001\n",
      "   8. tc_loss_ha_2002\n",
      "   9. tc_loss_ha_2003\n",
      "  10. tc_loss_ha_2004\n",
      "  11. tc_loss_ha_2005\n",
      "  12. tc_loss_ha_2006\n",
      "  13. tc_loss_ha_2007\n",
      "  14. tc_loss_ha_2008\n",
      "  15. tc_loss_ha_2009\n",
      "  16. tc_loss_ha_2010\n",
      "  17. tc_loss_ha_2011\n",
      "  18. tc_loss_ha_2012\n",
      "  19. tc_loss_ha_2013\n",
      "  20. tc_loss_ha_2014\n",
      "  21. tc_loss_ha_2015\n",
      "  22. tc_loss_ha_2016\n",
      "  23. tc_loss_ha_2017\n",
      "  24. tc_loss_ha_2018\n",
      "  25. tc_loss_ha_2019\n",
      "  26. tc_loss_ha_2020\n",
      "  27. tc_loss_ha_2021\n",
      "  28. tc_loss_ha_2022\n",
      "  29. tc_loss_ha_2023\n",
      "  30. tc_loss_ha_2024\n",
      "\n",
      "================================================================================\n",
      "First 5 rows:\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>threshold</th>\n",
       "      <th>area_ha</th>\n",
       "      <th>extent_2000_ha</th>\n",
       "      <th>extent_2010_ha</th>\n",
       "      <th>gain_2000-2012_ha</th>\n",
       "      <th>tc_loss_ha_2001</th>\n",
       "      <th>tc_loss_ha_2002</th>\n",
       "      <th>tc_loss_ha_2003</th>\n",
       "      <th>tc_loss_ha_2004</th>\n",
       "      <th>...</th>\n",
       "      <th>tc_loss_ha_2015</th>\n",
       "      <th>tc_loss_ha_2016</th>\n",
       "      <th>tc_loss_ha_2017</th>\n",
       "      <th>tc_loss_ha_2018</th>\n",
       "      <th>tc_loss_ha_2019</th>\n",
       "      <th>tc_loss_ha_2020</th>\n",
       "      <th>tc_loss_ha_2021</th>\n",
       "      <th>tc_loss_ha_2022</th>\n",
       "      <th>tc_loss_ha_2023</th>\n",
       "      <th>tc_loss_ha_2024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0</td>\n",
       "      <td>64383655</td>\n",
       "      <td>64383655</td>\n",
       "      <td>64383655</td>\n",
       "      <td>10738</td>\n",
       "      <td>103</td>\n",
       "      <td>214</td>\n",
       "      <td>267</td>\n",
       "      <td>226</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "      <td>16</td>\n",
       "      <td>133</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>10</td>\n",
       "      <td>64383655</td>\n",
       "      <td>432070</td>\n",
       "      <td>126231</td>\n",
       "      <td>10738</td>\n",
       "      <td>92</td>\n",
       "      <td>190</td>\n",
       "      <td>254</td>\n",
       "      <td>207</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>15</td>\n",
       "      <td>64383655</td>\n",
       "      <td>302629</td>\n",
       "      <td>106852</td>\n",
       "      <td>10738</td>\n",
       "      <td>91</td>\n",
       "      <td>186</td>\n",
       "      <td>248</td>\n",
       "      <td>205</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>39</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>20</td>\n",
       "      <td>64383655</td>\n",
       "      <td>284330</td>\n",
       "      <td>105718</td>\n",
       "      <td>10738</td>\n",
       "      <td>89</td>\n",
       "      <td>181</td>\n",
       "      <td>245</td>\n",
       "      <td>203</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>25</td>\n",
       "      <td>64383655</td>\n",
       "      <td>254843</td>\n",
       "      <td>72384</td>\n",
       "      <td>10738</td>\n",
       "      <td>89</td>\n",
       "      <td>180</td>\n",
       "      <td>244</td>\n",
       "      <td>202</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows \u00d7 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  threshold   area_ha  extent_2000_ha  extent_2010_ha  \\\n",
       "0  Afghanistan          0  64383655        64383655        64383655   \n",
       "1  Afghanistan         10  64383655          432070          126231   \n",
       "2  Afghanistan         15  64383655          302629          106852   \n",
       "3  Afghanistan         20  64383655          284330          105718   \n",
       "4  Afghanistan         25  64383655          254843           72384   \n",
       "\n",
       "   gain_2000-2012_ha  tc_loss_ha_2001  tc_loss_ha_2002  tc_loss_ha_2003  \\\n",
       "0              10738              103              214              267   \n",
       "1              10738               92              190              254   \n",
       "2              10738               91              186              248   \n",
       "3              10738               89              181              245   \n",
       "4              10738               89              180              244   \n",
       "\n",
       "   tc_loss_ha_2004  ...  tc_loss_ha_2015  tc_loss_ha_2016  tc_loss_ha_2017  \\\n",
       "0              226  ...                0                0                0   \n",
       "1              207  ...                0                0                0   \n",
       "2              205  ...                0                0                0   \n",
       "3              203  ...                0                0                0   \n",
       "4              202  ...                0                0                0   \n",
       "\n",
       "   tc_loss_ha_2018  tc_loss_ha_2019  tc_loss_ha_2020  tc_loss_ha_2021  \\\n",
       "0               31               25               46               47   \n",
       "1               28               19               40               37   \n",
       "2               28               19               39               32   \n",
       "3               28               18               39               32   \n",
       "4               27               18               38               27   \n",
       "\n",
       "   tc_loss_ha_2022  tc_loss_ha_2023  tc_loss_ha_2024  \n",
       "0               16              133              223  \n",
       "1                9               32               32  \n",
       "2                7               23               17  \n",
       "3                7               22               16  \n",
       "4                6               21               14  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Data Types:\n",
      "================================================================================\n",
      "country              object\n",
      "threshold             int64\n",
      "area_ha               int64\n",
      "extent_2000_ha        int64\n",
      "extent_2010_ha        int64\n",
      "gain_2000-2012_ha     int64\n",
      "tc_loss_ha_2001       int64\n",
      "tc_loss_ha_2002       int64\n",
      "tc_loss_ha_2003       int64\n",
      "tc_loss_ha_2004       int64\n",
      "tc_loss_ha_2005       int64\n",
      "tc_loss_ha_2006       int64\n",
      "tc_loss_ha_2007       int64\n",
      "tc_loss_ha_2008       int64\n",
      "tc_loss_ha_2009       int64\n",
      "tc_loss_ha_2010       int64\n",
      "tc_loss_ha_2011       int64\n",
      "tc_loss_ha_2012       int64\n",
      "tc_loss_ha_2013       int64\n",
      "tc_loss_ha_2014       int64\n",
      "tc_loss_ha_2015       int64\n",
      "tc_loss_ha_2016       int64\n",
      "tc_loss_ha_2017       int64\n",
      "tc_loss_ha_2018       int64\n",
      "tc_loss_ha_2019       int64\n",
      "tc_loss_ha_2020       int64\n",
      "tc_loss_ha_2021       int64\n",
      "tc_loss_ha_2022       int64\n",
      "tc_loss_ha_2023       int64\n",
      "tc_loss_ha_2024       int64\n",
      "dtype: object\n",
      "\n",
      "================================================================================\n",
      "Basic Statistics:\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>area_ha</th>\n",
       "      <th>extent_2000_ha</th>\n",
       "      <th>extent_2010_ha</th>\n",
       "      <th>gain_2000-2012_ha</th>\n",
       "      <th>tc_loss_ha_2001</th>\n",
       "      <th>tc_loss_ha_2002</th>\n",
       "      <th>tc_loss_ha_2003</th>\n",
       "      <th>tc_loss_ha_2004</th>\n",
       "      <th>tc_loss_ha_2005</th>\n",
       "      <th>...</th>\n",
       "      <th>tc_loss_ha_2015</th>\n",
       "      <th>tc_loss_ha_2016</th>\n",
       "      <th>tc_loss_ha_2017</th>\n",
       "      <th>tc_loss_ha_2018</th>\n",
       "      <th>tc_loss_ha_2019</th>\n",
       "      <th>tc_loss_ha_2020</th>\n",
       "      <th>tc_loss_ha_2021</th>\n",
       "      <th>tc_loss_ha_2022</th>\n",
       "      <th>tc_loss_ha_2023</th>\n",
       "      <th>tc_loss_ha_2024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1328.000000</td>\n",
       "      <td>1.328000e+03</td>\n",
       "      <td>1.328000e+03</td>\n",
       "      <td>1.328000e+03</td>\n",
       "      <td>1.328000e+03</td>\n",
       "      <td>1.328000e+03</td>\n",
       "      <td>1.328000e+03</td>\n",
       "      <td>1.328000e+03</td>\n",
       "      <td>1.328000e+03</td>\n",
       "      <td>1.328000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.328000e+03</td>\n",
       "      <td>1.328000e+03</td>\n",
       "      <td>1.328000e+03</td>\n",
       "      <td>1.328000e+03</td>\n",
       "      <td>1.328000e+03</td>\n",
       "      <td>1.328000e+03</td>\n",
       "      <td>1.328000e+03</td>\n",
       "      <td>1.328000e+03</td>\n",
       "      <td>1.328000e+03</td>\n",
       "      <td>1.328000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.125000</td>\n",
       "      <td>7.814805e+07</td>\n",
       "      <td>3.038020e+07</td>\n",
       "      <td>2.994347e+07</td>\n",
       "      <td>7.867308e+05</td>\n",
       "      <td>7.906576e+04</td>\n",
       "      <td>9.644243e+04</td>\n",
       "      <td>8.478851e+04</td>\n",
       "      <td>1.162822e+05</td>\n",
       "      <td>1.068036e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.153580e+05</td>\n",
       "      <td>1.756815e+05</td>\n",
       "      <td>1.745346e+05</td>\n",
       "      <td>1.469773e+05</td>\n",
       "      <td>1.438572e+05</td>\n",
       "      <td>1.553305e+05</td>\n",
       "      <td>1.498121e+05</td>\n",
       "      <td>1.356731e+05</td>\n",
       "      <td>1.686809e+05</td>\n",
       "      <td>1.776107e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22.499791</td>\n",
       "      <td>2.015752e+08</td>\n",
       "      <td>1.056704e+08</td>\n",
       "      <td>1.047382e+08</td>\n",
       "      <td>3.417373e+06</td>\n",
       "      <td>3.124548e+05</td>\n",
       "      <td>4.116669e+05</td>\n",
       "      <td>3.768918e+05</td>\n",
       "      <td>4.947177e+05</td>\n",
       "      <td>4.231545e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>3.906740e+05</td>\n",
       "      <td>6.453353e+05</td>\n",
       "      <td>6.079198e+05</td>\n",
       "      <td>5.459009e+05</td>\n",
       "      <td>4.588106e+05</td>\n",
       "      <td>5.799769e+05</td>\n",
       "      <td>6.139020e+05</td>\n",
       "      <td>4.909377e+05</td>\n",
       "      <td>7.502341e+05</td>\n",
       "      <td>6.924869e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.094000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13.750000</td>\n",
       "      <td>5.117777e+06</td>\n",
       "      <td>5.480255e+05</td>\n",
       "      <td>5.412700e+05</td>\n",
       "      <td>1.383200e+04</td>\n",
       "      <td>5.145000e+02</td>\n",
       "      <td>3.932500e+02</td>\n",
       "      <td>3.120000e+02</td>\n",
       "      <td>5.327500e+02</td>\n",
       "      <td>5.482500e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>3.230000e+02</td>\n",
       "      <td>6.187500e+02</td>\n",
       "      <td>7.272500e+02</td>\n",
       "      <td>5.825000e+02</td>\n",
       "      <td>5.377500e+02</td>\n",
       "      <td>6.575000e+02</td>\n",
       "      <td>5.275000e+02</td>\n",
       "      <td>3.860000e+02</td>\n",
       "      <td>8.287500e+02</td>\n",
       "      <td>6.737500e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22.500000</td>\n",
       "      <td>2.022587e+07</td>\n",
       "      <td>3.622986e+06</td>\n",
       "      <td>3.499126e+06</td>\n",
       "      <td>9.435900e+04</td>\n",
       "      <td>6.940500e+03</td>\n",
       "      <td>5.172000e+03</td>\n",
       "      <td>3.940500e+03</td>\n",
       "      <td>6.147500e+03</td>\n",
       "      <td>7.207500e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>7.497500e+03</td>\n",
       "      <td>1.421250e+04</td>\n",
       "      <td>1.631400e+04</td>\n",
       "      <td>1.156500e+04</td>\n",
       "      <td>1.108200e+04</td>\n",
       "      <td>1.195450e+04</td>\n",
       "      <td>9.935000e+03</td>\n",
       "      <td>9.190500e+03</td>\n",
       "      <td>1.396300e+04</td>\n",
       "      <td>1.095100e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>6.201997e+07</td>\n",
       "      <td>1.831977e+07</td>\n",
       "      <td>1.819886e+07</td>\n",
       "      <td>3.882400e+05</td>\n",
       "      <td>3.154525e+04</td>\n",
       "      <td>3.242225e+04</td>\n",
       "      <td>2.848925e+04</td>\n",
       "      <td>3.860275e+04</td>\n",
       "      <td>4.036250e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>5.140025e+04</td>\n",
       "      <td>1.063302e+05</td>\n",
       "      <td>9.793725e+04</td>\n",
       "      <td>7.669250e+04</td>\n",
       "      <td>7.689425e+04</td>\n",
       "      <td>8.074400e+04</td>\n",
       "      <td>7.072375e+04</td>\n",
       "      <td>6.527200e+04</td>\n",
       "      <td>7.677800e+04</td>\n",
       "      <td>8.178400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>1.689455e+09</td>\n",
       "      <td>1.689455e+09</td>\n",
       "      <td>1.689455e+09</td>\n",
       "      <td>3.722054e+07</td>\n",
       "      <td>2.933201e+06</td>\n",
       "      <td>3.715945e+06</td>\n",
       "      <td>3.489258e+06</td>\n",
       "      <td>4.133606e+06</td>\n",
       "      <td>3.675951e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.925679e+06</td>\n",
       "      <td>6.407238e+06</td>\n",
       "      <td>6.143920e+06</td>\n",
       "      <td>6.621833e+06</td>\n",
       "      <td>4.847068e+06</td>\n",
       "      <td>8.217252e+06</td>\n",
       "      <td>8.559449e+06</td>\n",
       "      <td>5.126743e+06</td>\n",
       "      <td>1.017602e+07</td>\n",
       "      <td>7.421840e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows \u00d7 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         threshold       area_ha  extent_2000_ha  extent_2010_ha  \\\n",
       "count  1328.000000  1.328000e+03    1.328000e+03    1.328000e+03   \n",
       "mean     28.125000  7.814805e+07    3.038020e+07    2.994347e+07   \n",
       "std      22.499791  2.015752e+08    1.056704e+08    1.047382e+08   \n",
       "min       0.000000  2.094000e+03    0.000000e+00    0.000000e+00   \n",
       "25%      13.750000  5.117777e+06    5.480255e+05    5.412700e+05   \n",
       "50%      22.500000  2.022587e+07    3.622986e+06    3.499126e+06   \n",
       "75%      35.000000  6.201997e+07    1.831977e+07    1.819886e+07   \n",
       "max      75.000000  1.689455e+09    1.689455e+09    1.689455e+09   \n",
       "\n",
       "       gain_2000-2012_ha  tc_loss_ha_2001  tc_loss_ha_2002  tc_loss_ha_2003  \\\n",
       "count       1.328000e+03     1.328000e+03     1.328000e+03     1.328000e+03   \n",
       "mean        7.867308e+05     7.906576e+04     9.644243e+04     8.478851e+04   \n",
       "std         3.417373e+06     3.124548e+05     4.116669e+05     3.768918e+05   \n",
       "min         0.000000e+00     0.000000e+00     0.000000e+00     0.000000e+00   \n",
       "25%         1.383200e+04     5.145000e+02     3.932500e+02     3.120000e+02   \n",
       "50%         9.435900e+04     6.940500e+03     5.172000e+03     3.940500e+03   \n",
       "75%         3.882400e+05     3.154525e+04     3.242225e+04     2.848925e+04   \n",
       "max         3.722054e+07     2.933201e+06     3.715945e+06     3.489258e+06   \n",
       "\n",
       "       tc_loss_ha_2004  tc_loss_ha_2005  ...  tc_loss_ha_2015  \\\n",
       "count     1.328000e+03     1.328000e+03  ...     1.328000e+03   \n",
       "mean      1.162822e+05     1.068036e+05  ...     1.153580e+05   \n",
       "std       4.947177e+05     4.231545e+05  ...     3.906740e+05   \n",
       "min       0.000000e+00     0.000000e+00  ...     0.000000e+00   \n",
       "25%       5.327500e+02     5.482500e+02  ...     3.230000e+02   \n",
       "50%       6.147500e+03     7.207500e+03  ...     7.497500e+03   \n",
       "75%       3.860275e+04     4.036250e+04  ...     5.140025e+04   \n",
       "max       4.133606e+06     3.675951e+06  ...     2.925679e+06   \n",
       "\n",
       "       tc_loss_ha_2016  tc_loss_ha_2017  tc_loss_ha_2018  tc_loss_ha_2019  \\\n",
       "count     1.328000e+03     1.328000e+03     1.328000e+03     1.328000e+03   \n",
       "mean      1.756815e+05     1.745346e+05     1.469773e+05     1.438572e+05   \n",
       "std       6.453353e+05     6.079198e+05     5.459009e+05     4.588106e+05   \n",
       "min       0.000000e+00     0.000000e+00     0.000000e+00     0.000000e+00   \n",
       "25%       6.187500e+02     7.272500e+02     5.825000e+02     5.377500e+02   \n",
       "50%       1.421250e+04     1.631400e+04     1.156500e+04     1.108200e+04   \n",
       "75%       1.063302e+05     9.793725e+04     7.669250e+04     7.689425e+04   \n",
       "max       6.407238e+06     6.143920e+06     6.621833e+06     4.847068e+06   \n",
       "\n",
       "       tc_loss_ha_2020  tc_loss_ha_2021  tc_loss_ha_2022  tc_loss_ha_2023  \\\n",
       "count     1.328000e+03     1.328000e+03     1.328000e+03     1.328000e+03   \n",
       "mean      1.553305e+05     1.498121e+05     1.356731e+05     1.686809e+05   \n",
       "std       5.799769e+05     6.139020e+05     4.909377e+05     7.502341e+05   \n",
       "min       0.000000e+00     0.000000e+00     0.000000e+00     0.000000e+00   \n",
       "25%       6.575000e+02     5.275000e+02     3.860000e+02     8.287500e+02   \n",
       "50%       1.195450e+04     9.935000e+03     9.190500e+03     1.396300e+04   \n",
       "75%       8.074400e+04     7.072375e+04     6.527200e+04     7.677800e+04   \n",
       "max       8.217252e+06     8.559449e+06     5.126743e+06     1.017602e+07   \n",
       "\n",
       "       tc_loss_ha_2024  \n",
       "count     1.328000e+03  \n",
       "mean      1.776107e+05  \n",
       "std       6.924869e+05  \n",
       "min       0.000000e+00  \n",
       "25%       6.737500e+02  \n",
       "50%       1.095100e+04  \n",
       "75%       8.178400e+04  \n",
       "max       7.421840e+06  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_tree_cover_loss = excel_file.parse(\"Country tree cover loss\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"COUNTRY TREE COVER LOSS - RAW DATA\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Shape: {df_tree_cover_loss.shape[0]:,} rows \u00d7 {df_tree_cover_loss.shape[1]} columns\")\n",
    "print(f\"\\nColumn names ({len(df_tree_cover_loss.columns)}):\")\n",
    "for i, col in enumerate(df_tree_cover_loss.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"First 5 rows:\")\n",
    "print(\"=\"*80)\n",
    "display(df_tree_cover_loss.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Data Types:\")\n",
    "print(\"=\"*80)\n",
    "print(df_tree_cover_loss.dtypes)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Basic Statistics:\")\n",
    "print(\"=\"*80)\n",
    "display(df_tree_cover_loss.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8080d02e",
   "metadata": {},
   "source": [
    "**Findings:**\n",
    "\n",
    "From exploring the Country Tree Cover Loss sheet, we discovered:\n",
    "\n",
    "1. **Data Structure:**\n",
    "   - The sheet contains **1,328 rows and 30 columns**\n",
    "   - The data is in **wide format** with separate columns for each year (`tc_loss_ha_2001` through `tc_loss_ha_2024`)\n",
    "   - This represents 24 years of data (2001-2024) plus 6 metadata columns\n",
    "   - The wide format will need to be converted to long format during data preparation\n",
    "\n",
    "2. **Key Columns Identified:**\n",
    "   - `country`: Country names (object/string type)\n",
    "   - `threshold`: Canopy density threshold values (int64 type, mean: 28.125, suggesting values like 0, 25, 30, 50, 75)\n",
    "   - `area_ha`: Total area in hectares (int64)\n",
    "   - `extent_2000_ha`: Tree cover extent in year 2000 (int64)\n",
    "   - `extent_2010_ha`: Tree cover extent in year 2010 (int64)\n",
    "   - `gain_2000-2012_ha`: Tree cover gain between 2000-2012 (int64)\n",
    "   - **24 year-based columns**: `tc_loss_ha_2001` through `tc_loss_ha_2024` representing annual tree cover loss\n",
    "\n",
    "3. **Data Types:**\n",
    "   - All numeric columns are stored as **int64** (integers), which is appropriate for hectare measurements\n",
    "   - Country names are stored as **object** (strings)\n",
    "   - No float types, which simplifies data handling and avoids precision issues\n",
    "   - All data types are consistent and appropriate for the data content\n",
    "\n",
    "4. **Statistical Summary:**\n",
    "   - **Threshold**: Mean of 28.125, indicating multiple threshold values are used\n",
    "   - **Area**: Mean area of ~78 million hectares per row (very large, likely country-level aggregations)\n",
    "   - **Extent 2000**: Mean of ~30 million hectares of tree cover in 2000\n",
    "   - **Extent 2010**: Mean of ~30 million hectares of tree cover in 2010 (slight decrease)\n",
    "   - The large standard deviations indicate significant variation across countries\n",
    "   - Year columns (2001-2024) contain loss values that will need to be unpivoted\n",
    "\n",
    "**Implication for Data Preparation:** \n",
    "- We'll need to reshape this data from wide to long format, extracting years from column names (`tc_loss_ha_2001` \u2192 year: 2001, value: [loss amount])\n",
    "- The 24 year columns will become 24 rows per country-threshold combination\n",
    "- After reshaping, we expect approximately 1,328 \u00d7 24 = ~31,872 rows (if all years have data)\n",
    "- All numeric columns are already integers, so no type conversion needed\n",
    "- The metadata columns (area_ha, extent_2000_ha, extent_2010_ha, gain_2000-2012_ha) will need to be preserved during reshaping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec7494f2c7c06d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T19:02:11.690542Z",
     "start_time": "2025-11-10T19:02:11.680049Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u26a0\ufe0f No column found for 'tree_cover_extent_ha'. Check your dataset columns:\n",
      "['country', 'threshold', 'area_ha_x', 'extent_2000_ha', 'extent_2010_ha', 'gain_2000-2012_ha', 'tree_cover_loss_ha', 'year', 'area_ha_y', 'primary_forest_loss_ha', 'hard_commodities', 'logging', 'other_natural_disturbances', 'permanent_agriculture', 'settlements_infrastructure', 'shifting_cultivation', 'wildfire', 'umd_tree_cover_extent_2000__ha', 'gfw_aboveground_carbon_stocks_2000__mg_c', 'avg_gfw_aboveground_carbon_stocks_2000__mg_c_ha-1', 'gfw_forest_carbon_gross_emissions__mg_co2e_yr-1', 'gfw_forest_carbon_gross_removals__mg_co2_yr-1', 'gfw_forest_carbon_net_flux__mg_co2e_yr-1', 'carbon_gross_emissions_MgCO2e']\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"MISSING VALUES ANALYSIS:\")\n",
    "print(\"=\"*80)\n",
    "missing = df_tree_cover_loss.isnull().sum()\n",
    "missing_pct = (missing / len(df_tree_cover_loss)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing.index,\n",
    "    'Missing Count': missing.values,\n",
    "    'Missing Percentage': missing_pct.values\n",
    "}).sort_values('Missing Count', ascending=False)\n",
    "\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0]\n",
    "if len(missing_df) > 0:\n",
    "    display(missing_df)\n",
    "else:\n",
    "    print(\"\u2705 No missing values found!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"UNIQUE VALUES:\")\n",
    "print(\"=\"*80)\n",
    "if 'country' in df_tree_cover_loss.columns:\n",
    "    print(f\"Number of countries: {df_tree_cover_loss['country'].nunique()}\")\n",
    "    print(f\"Countries: {sorted(df_tree_cover_loss['country'].unique())}\")\n",
    "\n",
    "if 'threshold' in df_tree_cover_loss.columns:\n",
    "    print(f\"\\nThreshold values: {sorted(df_tree_cover_loss['threshold'].unique())}\")\n",
    "\n",
    "year_cols = [col for col in df_tree_cover_loss.columns if '200' in col or '201' in col or '202' in col]\n",
    "print(f\"\\nYear columns found: {len(year_cols)}\")\n",
    "if year_cols:\n",
    "    print(f\"Year range: {year_cols[0]} to {year_cols[-1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc7155084872abe",
   "metadata": {},
   "source": [
    "## Step 4: Exploring Country Primary Loss Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a152cd28986df83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T13:53:29.269335Z",
     "start_time": "2025-11-29T13:53:28.840343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COUNTRY PRIMARY LOSS - RAW DATA\n",
      "================================================================================\n",
      "Shape: 76 rows \u00d7 26 columns\n",
      "\n",
      "Column names (26):\n",
      "   1. country\n",
      "   2. threshold\n",
      "   3. area__ha\n",
      "   4. tc_loss_ha_2002\n",
      "   5. tc_loss_ha_2003\n",
      "   6. tc_loss_ha_2004\n",
      "   7. tc_loss_ha_2005\n",
      "   8. tc_loss_ha_2006\n",
      "   9. tc_loss_ha_2007\n",
      "  10. tc_loss_ha_2008\n",
      "  11. tc_loss_ha_2009\n",
      "  12. tc_loss_ha_2010\n",
      "  13. tc_loss_ha_2011\n",
      "  14. tc_loss_ha_2012\n",
      "  15. tc_loss_ha_2013\n",
      "  16. tc_loss_ha_2014\n",
      "  17. tc_loss_ha_2015\n",
      "  18. tc_loss_ha_2016\n",
      "  19. tc_loss_ha_2017\n",
      "  20. tc_loss_ha_2018\n",
      "  21. tc_loss_ha_2019\n",
      "  22. tc_loss_ha_2020\n",
      "  23. tc_loss_ha_2021\n",
      "  24. tc_loss_ha_2022\n",
      "  25. tc_loss_ha_2023\n",
      "  26. tc_loss_ha_2024\n",
      "\n",
      "================================================================================\n",
      "First 5 rows:\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>threshold</th>\n",
       "      <th>area__ha</th>\n",
       "      <th>tc_loss_ha_2002</th>\n",
       "      <th>tc_loss_ha_2003</th>\n",
       "      <th>tc_loss_ha_2004</th>\n",
       "      <th>tc_loss_ha_2005</th>\n",
       "      <th>tc_loss_ha_2006</th>\n",
       "      <th>tc_loss_ha_2007</th>\n",
       "      <th>tc_loss_ha_2008</th>\n",
       "      <th>...</th>\n",
       "      <th>tc_loss_ha_2015</th>\n",
       "      <th>tc_loss_ha_2016</th>\n",
       "      <th>tc_loss_ha_2017</th>\n",
       "      <th>tc_loss_ha_2018</th>\n",
       "      <th>tc_loss_ha_2019</th>\n",
       "      <th>tc_loss_ha_2020</th>\n",
       "      <th>tc_loss_ha_2021</th>\n",
       "      <th>tc_loss_ha_2022</th>\n",
       "      <th>tc_loss_ha_2023</th>\n",
       "      <th>tc_loss_ha_2024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Angola</td>\n",
       "      <td>30</td>\n",
       "      <td>2458061</td>\n",
       "      <td>3499</td>\n",
       "      <td>2963</td>\n",
       "      <td>2354</td>\n",
       "      <td>3110</td>\n",
       "      <td>1400</td>\n",
       "      <td>8060</td>\n",
       "      <td>2699</td>\n",
       "      <td>...</td>\n",
       "      <td>8998</td>\n",
       "      <td>12040</td>\n",
       "      <td>11166</td>\n",
       "      <td>13507</td>\n",
       "      <td>9995</td>\n",
       "      <td>8895</td>\n",
       "      <td>24326</td>\n",
       "      <td>15576</td>\n",
       "      <td>17627</td>\n",
       "      <td>13660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>30</td>\n",
       "      <td>4418724</td>\n",
       "      <td>9318</td>\n",
       "      <td>14459</td>\n",
       "      <td>28090</td>\n",
       "      <td>31429</td>\n",
       "      <td>24095</td>\n",
       "      <td>18687</td>\n",
       "      <td>47067</td>\n",
       "      <td>...</td>\n",
       "      <td>10547</td>\n",
       "      <td>15247</td>\n",
       "      <td>17202</td>\n",
       "      <td>9496</td>\n",
       "      <td>8983</td>\n",
       "      <td>20847</td>\n",
       "      <td>11921</td>\n",
       "      <td>21388</td>\n",
       "      <td>11473</td>\n",
       "      <td>12103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>30</td>\n",
       "      <td>13977</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>30</td>\n",
       "      <td>101114</td>\n",
       "      <td>619</td>\n",
       "      <td>266</td>\n",
       "      <td>347</td>\n",
       "      <td>306</td>\n",
       "      <td>677</td>\n",
       "      <td>369</td>\n",
       "      <td>240</td>\n",
       "      <td>...</td>\n",
       "      <td>205</td>\n",
       "      <td>345</td>\n",
       "      <td>414</td>\n",
       "      <td>358</td>\n",
       "      <td>387</td>\n",
       "      <td>459</td>\n",
       "      <td>308</td>\n",
       "      <td>307</td>\n",
       "      <td>743</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Belize</td>\n",
       "      <td>30</td>\n",
       "      <td>1165487</td>\n",
       "      <td>5570</td>\n",
       "      <td>2993</td>\n",
       "      <td>2108</td>\n",
       "      <td>3206</td>\n",
       "      <td>1899</td>\n",
       "      <td>4140</td>\n",
       "      <td>3632</td>\n",
       "      <td>...</td>\n",
       "      <td>6606</td>\n",
       "      <td>11511</td>\n",
       "      <td>6616</td>\n",
       "      <td>4781</td>\n",
       "      <td>8772</td>\n",
       "      <td>16087</td>\n",
       "      <td>4560</td>\n",
       "      <td>4033</td>\n",
       "      <td>11667</td>\n",
       "      <td>21137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows \u00d7 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      country  threshold  area__ha  tc_loss_ha_2002  tc_loss_ha_2003  \\\n",
       "0      Angola         30   2458061             3499             2963   \n",
       "1   Argentina         30   4418724             9318            14459   \n",
       "2   Australia         30     13977                0                0   \n",
       "3  Bangladesh         30    101114              619              266   \n",
       "4      Belize         30   1165487             5570             2993   \n",
       "\n",
       "   tc_loss_ha_2004  tc_loss_ha_2005  tc_loss_ha_2006  tc_loss_ha_2007  \\\n",
       "0             2354             3110             1400             8060   \n",
       "1            28090            31429            24095            18687   \n",
       "2                0                0               25                0   \n",
       "3              347              306              677              369   \n",
       "4             2108             3206             1899             4140   \n",
       "\n",
       "   tc_loss_ha_2008  ...  tc_loss_ha_2015  tc_loss_ha_2016  tc_loss_ha_2017  \\\n",
       "0             2699  ...             8998            12040            11166   \n",
       "1            47067  ...            10547            15247            17202   \n",
       "2                0  ...                5                0                0   \n",
       "3              240  ...              205              345              414   \n",
       "4             3632  ...             6606            11511             6616   \n",
       "\n",
       "   tc_loss_ha_2018  tc_loss_ha_2019  tc_loss_ha_2020  tc_loss_ha_2021  \\\n",
       "0            13507             9995             8895            24326   \n",
       "1             9496             8983            20847            11921   \n",
       "2                0                5                0                0   \n",
       "3              358              387              459              308   \n",
       "4             4781             8772            16087             4560   \n",
       "\n",
       "   tc_loss_ha_2022  tc_loss_ha_2023  tc_loss_ha_2024  \n",
       "0            15576            17627            13660  \n",
       "1            21388            11473            12103  \n",
       "2                0                0                0  \n",
       "3              307              743              467  \n",
       "4             4033            11667            21137  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Data Types:\n",
      "================================================================================\n",
      "country            object\n",
      "threshold           int64\n",
      "area__ha            int64\n",
      "tc_loss_ha_2002     int64\n",
      "tc_loss_ha_2003     int64\n",
      "tc_loss_ha_2004     int64\n",
      "tc_loss_ha_2005     int64\n",
      "tc_loss_ha_2006     int64\n",
      "tc_loss_ha_2007     int64\n",
      "tc_loss_ha_2008     int64\n",
      "tc_loss_ha_2009     int64\n",
      "tc_loss_ha_2010     int64\n",
      "tc_loss_ha_2011     int64\n",
      "tc_loss_ha_2012     int64\n",
      "tc_loss_ha_2013     int64\n",
      "tc_loss_ha_2014     int64\n",
      "tc_loss_ha_2015     int64\n",
      "tc_loss_ha_2016     int64\n",
      "tc_loss_ha_2017     int64\n",
      "tc_loss_ha_2018     int64\n",
      "tc_loss_ha_2019     int64\n",
      "tc_loss_ha_2020     int64\n",
      "tc_loss_ha_2021     int64\n",
      "tc_loss_ha_2022     int64\n",
      "tc_loss_ha_2023     int64\n",
      "tc_loss_ha_2024     int64\n",
      "dtype: object\n",
      "\n",
      "================================================================================\n",
      "Basic Statistics:\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>area__ha</th>\n",
       "      <th>tc_loss_ha_2002</th>\n",
       "      <th>tc_loss_ha_2003</th>\n",
       "      <th>tc_loss_ha_2004</th>\n",
       "      <th>tc_loss_ha_2005</th>\n",
       "      <th>tc_loss_ha_2006</th>\n",
       "      <th>tc_loss_ha_2007</th>\n",
       "      <th>tc_loss_ha_2008</th>\n",
       "      <th>tc_loss_ha_2009</th>\n",
       "      <th>...</th>\n",
       "      <th>tc_loss_ha_2015</th>\n",
       "      <th>tc_loss_ha_2016</th>\n",
       "      <th>tc_loss_ha_2017</th>\n",
       "      <th>tc_loss_ha_2018</th>\n",
       "      <th>tc_loss_ha_2019</th>\n",
       "      <th>tc_loss_ha_2020</th>\n",
       "      <th>tc_loss_ha_2021</th>\n",
       "      <th>tc_loss_ha_2022</th>\n",
       "      <th>tc_loss_ha_2023</th>\n",
       "      <th>tc_loss_ha_2024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>76.0</td>\n",
       "      <td>7.600000e+01</td>\n",
       "      <td>7.600000e+01</td>\n",
       "      <td>7.600000e+01</td>\n",
       "      <td>7.600000e+01</td>\n",
       "      <td>7.600000e+01</td>\n",
       "      <td>7.600000e+01</td>\n",
       "      <td>7.600000e+01</td>\n",
       "      <td>7.600000e+01</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>7.600000e+01</td>\n",
       "      <td>7.600000e+01</td>\n",
       "      <td>7.600000e+01</td>\n",
       "      <td>7.600000e+01</td>\n",
       "      <td>7.600000e+01</td>\n",
       "      <td>7.600000e+01</td>\n",
       "      <td>7.600000e+01</td>\n",
       "      <td>7.600000e+01</td>\n",
       "      <td>7.600000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30.0</td>\n",
       "      <td>1.349796e+07</td>\n",
       "      <td>3.500986e+04</td>\n",
       "      <td>3.268253e+04</td>\n",
       "      <td>4.462941e+04</td>\n",
       "      <td>4.370550e+04</td>\n",
       "      <td>3.695367e+04</td>\n",
       "      <td>3.814787e+04</td>\n",
       "      <td>3.563292e+04</td>\n",
       "      <td>36765.184211</td>\n",
       "      <td>...</td>\n",
       "      <td>38528.013158</td>\n",
       "      <td>8.050946e+04</td>\n",
       "      <td>6.532487e+04</td>\n",
       "      <td>4.792633e+04</td>\n",
       "      <td>4.931018e+04</td>\n",
       "      <td>5.531720e+04</td>\n",
       "      <td>4.926511e+04</td>\n",
       "      <td>5.407901e+04</td>\n",
       "      <td>4.911196e+04</td>\n",
       "      <td>8.849616e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.300172e+07</td>\n",
       "      <td>1.883565e+05</td>\n",
       "      <td>1.816783e+05</td>\n",
       "      <td>2.367232e+05</td>\n",
       "      <td>2.157229e+05</td>\n",
       "      <td>1.706006e+05</td>\n",
       "      <td>1.452392e+05</td>\n",
       "      <td>1.354756e+05</td>\n",
       "      <td>116080.074035</td>\n",
       "      <td>...</td>\n",
       "      <td>126231.483498</td>\n",
       "      <td>3.430140e+05</td>\n",
       "      <td>2.536957e+05</td>\n",
       "      <td>1.680912e+05</td>\n",
       "      <td>1.702689e+05</td>\n",
       "      <td>2.058852e+05</td>\n",
       "      <td>1.885591e+05</td>\n",
       "      <td>2.149624e+05</td>\n",
       "      <td>1.549588e+05</td>\n",
       "      <td>3.671704e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>30.0</td>\n",
       "      <td>1.653000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>30.0</td>\n",
       "      <td>2.271512e+05</td>\n",
       "      <td>1.325000e+02</td>\n",
       "      <td>1.225000e+02</td>\n",
       "      <td>2.035000e+02</td>\n",
       "      <td>2.170000e+02</td>\n",
       "      <td>2.455000e+02</td>\n",
       "      <td>1.845000e+02</td>\n",
       "      <td>2.227500e+02</td>\n",
       "      <td>445.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>253.750000</td>\n",
       "      <td>5.015000e+02</td>\n",
       "      <td>5.145000e+02</td>\n",
       "      <td>3.417500e+02</td>\n",
       "      <td>3.247500e+02</td>\n",
       "      <td>3.065000e+02</td>\n",
       "      <td>3.012500e+02</td>\n",
       "      <td>2.927500e+02</td>\n",
       "      <td>2.740000e+02</td>\n",
       "      <td>3.660000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30.0</td>\n",
       "      <td>1.833100e+06</td>\n",
       "      <td>2.029500e+03</td>\n",
       "      <td>1.582500e+03</td>\n",
       "      <td>2.277000e+03</td>\n",
       "      <td>2.320000e+03</td>\n",
       "      <td>2.528500e+03</td>\n",
       "      <td>3.063500e+03</td>\n",
       "      <td>3.677500e+03</td>\n",
       "      <td>3729.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>3392.500000</td>\n",
       "      <td>4.904000e+03</td>\n",
       "      <td>7.123000e+03</td>\n",
       "      <td>4.061500e+03</td>\n",
       "      <td>5.047500e+03</td>\n",
       "      <td>4.094000e+03</td>\n",
       "      <td>4.050000e+03</td>\n",
       "      <td>3.952000e+03</td>\n",
       "      <td>4.538500e+03</td>\n",
       "      <td>4.598000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>30.0</td>\n",
       "      <td>7.487047e+06</td>\n",
       "      <td>1.013250e+04</td>\n",
       "      <td>1.014375e+04</td>\n",
       "      <td>1.197275e+04</td>\n",
       "      <td>1.202100e+04</td>\n",
       "      <td>1.418450e+04</td>\n",
       "      <td>1.843200e+04</td>\n",
       "      <td>1.528925e+04</td>\n",
       "      <td>19996.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>16938.250000</td>\n",
       "      <td>4.590225e+04</td>\n",
       "      <td>3.110525e+04</td>\n",
       "      <td>2.709850e+04</td>\n",
       "      <td>3.070975e+04</td>\n",
       "      <td>3.433400e+04</td>\n",
       "      <td>2.444950e+04</td>\n",
       "      <td>2.350000e+04</td>\n",
       "      <td>2.459825e+04</td>\n",
       "      <td>4.037175e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.0</td>\n",
       "      <td>3.432610e+08</td>\n",
       "      <td>1.621738e+06</td>\n",
       "      <td>1.570540e+06</td>\n",
       "      <td>2.016350e+06</td>\n",
       "      <td>1.824217e+06</td>\n",
       "      <td>1.415536e+06</td>\n",
       "      <td>1.149515e+06</td>\n",
       "      <td>1.075087e+06</td>\n",
       "      <td>700115.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>828839.000000</td>\n",
       "      <td>2.830943e+06</td>\n",
       "      <td>2.134474e+06</td>\n",
       "      <td>1.347176e+06</td>\n",
       "      <td>1.361053e+06</td>\n",
       "      <td>1.703491e+06</td>\n",
       "      <td>1.546964e+06</td>\n",
       "      <td>1.772214e+06</td>\n",
       "      <td>1.136250e+06</td>\n",
       "      <td>2.823646e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows \u00d7 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold      area__ha  tc_loss_ha_2002  tc_loss_ha_2003  \\\n",
       "count       76.0  7.600000e+01     7.600000e+01     7.600000e+01   \n",
       "mean        30.0  1.349796e+07     3.500986e+04     3.268253e+04   \n",
       "std          0.0  4.300172e+07     1.883565e+05     1.816783e+05   \n",
       "min         30.0  1.653000e+03     0.000000e+00     0.000000e+00   \n",
       "25%         30.0  2.271512e+05     1.325000e+02     1.225000e+02   \n",
       "50%         30.0  1.833100e+06     2.029500e+03     1.582500e+03   \n",
       "75%         30.0  7.487047e+06     1.013250e+04     1.014375e+04   \n",
       "max         30.0  3.432610e+08     1.621738e+06     1.570540e+06   \n",
       "\n",
       "       tc_loss_ha_2004  tc_loss_ha_2005  tc_loss_ha_2006  tc_loss_ha_2007  \\\n",
       "count     7.600000e+01     7.600000e+01     7.600000e+01     7.600000e+01   \n",
       "mean      4.462941e+04     4.370550e+04     3.695367e+04     3.814787e+04   \n",
       "std       2.367232e+05     2.157229e+05     1.706006e+05     1.452392e+05   \n",
       "min       0.000000e+00     0.000000e+00     0.000000e+00     0.000000e+00   \n",
       "25%       2.035000e+02     2.170000e+02     2.455000e+02     1.845000e+02   \n",
       "50%       2.277000e+03     2.320000e+03     2.528500e+03     3.063500e+03   \n",
       "75%       1.197275e+04     1.202100e+04     1.418450e+04     1.843200e+04   \n",
       "max       2.016350e+06     1.824217e+06     1.415536e+06     1.149515e+06   \n",
       "\n",
       "       tc_loss_ha_2008  tc_loss_ha_2009  ...  tc_loss_ha_2015  \\\n",
       "count     7.600000e+01        76.000000  ...        76.000000   \n",
       "mean      3.563292e+04     36765.184211  ...     38528.013158   \n",
       "std       1.354756e+05    116080.074035  ...    126231.483498   \n",
       "min       0.000000e+00         0.000000  ...         0.000000   \n",
       "25%       2.227500e+02       445.250000  ...       253.750000   \n",
       "50%       3.677500e+03      3729.500000  ...      3392.500000   \n",
       "75%       1.528925e+04     19996.250000  ...     16938.250000   \n",
       "max       1.075087e+06    700115.000000  ...    828839.000000   \n",
       "\n",
       "       tc_loss_ha_2016  tc_loss_ha_2017  tc_loss_ha_2018  tc_loss_ha_2019  \\\n",
       "count     7.600000e+01     7.600000e+01     7.600000e+01     7.600000e+01   \n",
       "mean      8.050946e+04     6.532487e+04     4.792633e+04     4.931018e+04   \n",
       "std       3.430140e+05     2.536957e+05     1.680912e+05     1.702689e+05   \n",
       "min       0.000000e+00     0.000000e+00     0.000000e+00     0.000000e+00   \n",
       "25%       5.015000e+02     5.145000e+02     3.417500e+02     3.247500e+02   \n",
       "50%       4.904000e+03     7.123000e+03     4.061500e+03     5.047500e+03   \n",
       "75%       4.590225e+04     3.110525e+04     2.709850e+04     3.070975e+04   \n",
       "max       2.830943e+06     2.134474e+06     1.347176e+06     1.361053e+06   \n",
       "\n",
       "       tc_loss_ha_2020  tc_loss_ha_2021  tc_loss_ha_2022  tc_loss_ha_2023  \\\n",
       "count     7.600000e+01     7.600000e+01     7.600000e+01     7.600000e+01   \n",
       "mean      5.531720e+04     4.926511e+04     5.407901e+04     4.911196e+04   \n",
       "std       2.058852e+05     1.885591e+05     2.149624e+05     1.549588e+05   \n",
       "min       0.000000e+00     0.000000e+00     0.000000e+00     0.000000e+00   \n",
       "25%       3.065000e+02     3.012500e+02     2.927500e+02     2.740000e+02   \n",
       "50%       4.094000e+03     4.050000e+03     3.952000e+03     4.538500e+03   \n",
       "75%       3.433400e+04     2.444950e+04     2.350000e+04     2.459825e+04   \n",
       "max       1.703491e+06     1.546964e+06     1.772214e+06     1.136250e+06   \n",
       "\n",
       "       tc_loss_ha_2024  \n",
       "count     7.600000e+01  \n",
       "mean      8.849616e+04  \n",
       "std       3.671704e+05  \n",
       "min       0.000000e+00  \n",
       "25%       3.660000e+02  \n",
       "50%       4.598000e+03  \n",
       "75%       4.037175e+04  \n",
       "max       2.823646e+06  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MISSING VALUES ANALYSIS:\n",
      "================================================================================\n",
      "\u2705 No missing values found!\n",
      "\n",
      "================================================================================\n",
      "UNIQUE VALUES:\n",
      "================================================================================\n",
      "Number of countries: 76\n",
      "Countries: ['Angola', 'Argentina', 'Australia', 'Bangladesh', 'Belize', 'Benin', 'Bhutan', 'Bolivia', 'Brazil', 'Brunei', 'Burundi', 'Cambodia', 'Cameroon', 'Central African Republic', 'China', 'Colombia', 'Costa Rica', 'Cuba', \"C\u00f4te d'Ivoire\", 'Democratic Republic of the Congo', 'Dominican Republic', 'Ecuador', 'El Salvador', 'Equatorial Guinea', 'Ethiopia', 'Fiji', 'French Guiana', 'Gabon', 'Ghana', 'Guadeloupe', 'Guatemala', 'Guinea', 'Guinea-Bissau', 'Guyana', 'Haiti', 'Honduras', 'India', 'Indonesia', 'Kenya', 'Laos', 'Liberia', 'Madagascar', 'Malawi', 'Malaysia', 'Martinique', 'Mozambique', 'Myanmar', 'M\u00e9xico', 'Nepal', 'Nicaragua', 'Nigeria', 'Panama', 'Papua New Guinea', 'Paraguay', 'Peru', 'Philippines', 'Republic of the Congo', 'Rwanda', 'Senegal', 'Sierra Leone', 'Solomon Islands', 'South Africa', 'South Sudan', 'Sri Lanka', 'Suriname', 'Tanzania', 'Thailand', 'Togo', 'Uganda', 'United States', 'Vanuatu', 'Venezuela', 'Vietnam', 'Virgin Islands, U.S.', 'Zambia', 'Zimbabwe']\n",
      "\n",
      "Threshold values: [np.int64(30)]\n",
      "\n",
      "Year columns found: 23\n",
      "Year range: tc_loss_ha_2002 to tc_loss_ha_2024\n"
     ]
    }
   ],
   "source": [
    "df_primary_loss = excel_file.parse(\"Country primary loss\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"COUNTRY PRIMARY LOSS - RAW DATA\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Shape: {df_primary_loss.shape[0]:,} rows \u00d7 {df_primary_loss.shape[1]} columns\")\n",
    "print(f\"\\nColumn names ({len(df_primary_loss.columns)}):\")\n",
    "for i, col in enumerate(df_primary_loss.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"First 5 rows:\")\n",
    "print(\"=\"*80)\n",
    "display(df_primary_loss.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Data Types:\")\n",
    "print(\"=\"*80)\n",
    "print(df_primary_loss.dtypes)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Basic Statistics:\")\n",
    "print(\"=\"*80)\n",
    "display(df_primary_loss.describe())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MISSING VALUES ANALYSIS:\")\n",
    "print(\"=\"*80)\n",
    "missing = df_primary_loss.isnull().sum()\n",
    "missing_pct = (missing / len(df_primary_loss)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing.index,\n",
    "    'Missing Count': missing.values,\n",
    "    'Missing Percentage': missing_pct.values\n",
    "}).sort_values('Missing Count', ascending=False)\n",
    "\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0]\n",
    "if len(missing_df) > 0:\n",
    "    display(missing_df)\n",
    "else:\n",
    "    print(\"\u2705 No missing values found!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"UNIQUE VALUES:\")\n",
    "print(\"=\"*80)\n",
    "if 'country' in df_primary_loss.columns:\n",
    "    print(f\"Number of countries: {df_primary_loss['country'].nunique()}\")\n",
    "    print(f\"Countries: {sorted(df_primary_loss['country'].unique())}\")\n",
    "\n",
    "if 'threshold' in df_primary_loss.columns:\n",
    "    print(f\"\\nThreshold values: {sorted(df_primary_loss['threshold'].unique())}\")\n",
    "\n",
    "year_cols = [col for col in df_primary_loss.columns if '200' in col or '201' in col or '202' in col]\n",
    "print(f\"\\nYear columns found: {len(year_cols)}\")\n",
    "if year_cols:\n",
    "    print(f\"Year range: {year_cols[0]} to {year_cols[-1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154d97f2f984223f",
   "metadata": {},
   "source": [
    "**Findings:**\n",
    "\n",
    "From exploring the Country Primary Loss sheet, we discovered:\n",
    "\n",
    "1. **Data Structure:**\n",
    "   - The sheet contains **76 rows and 26 columns**\n",
    "   - The data is in **wide format** with separate columns for each year (`tc_loss_ha_2002` through `tc_loss_ha_2024`)\n",
    "   - **Important difference**: Year columns start at 2002 (not 2001), so we have 23 years of data (2002-2024) plus 3 metadata columns\n",
    "   - This is significantly smaller than tree cover loss (76 rows vs. 1,328 rows), indicating fewer countries have primary forest data\n",
    "   - The wide format will need to be converted to long format during data preparation\n",
    "\n",
    "2. **Key Columns Identified:**\n",
    "   - `country`: Country names (object/string type)\n",
    "   - `threshold`: Canopy density threshold values (int64 type) - **Only threshold 30 is present** (unlike tree cover loss which has multiple thresholds)\n",
    "   - `area__ha`: Total area in hectares (int64) - Note: column name uses double underscore `area__ha` (different from tree cover loss which uses `area_ha`)\n",
    "   - **23 year-based columns**: `tc_loss_ha_2002` through `tc_loss_ha_2024` representing annual primary forest loss\n",
    "   - **Missing 2001 data**: Unlike tree cover loss, primary loss data starts from 2002\n",
    "\n",
    "3. **Data Types:**\n",
    "   - All numeric columns are stored as **int64** (integers), which is appropriate for hectare measurements\n",
    "   - Country names are stored as **object** (strings)\n",
    "   - Data types are consistent with tree cover loss sheet, which will facilitate merging\n",
    "   - No float types, simplifying data handling\n",
    "\n",
    "4. **Statistical Summary:**\n",
    "   - **Threshold**: All values are 30 (mean: 30.0, std: 0.0) - only one threshold value in this dataset\n",
    "   - **Area**: Mean area of ~13.5 million hectares per row (smaller than tree cover loss's ~78 million, reflecting fewer/larger primary forest countries)\n",
    "   - **Primary Loss Values**: Mean loss ranges from ~35,000 hectares (2002) to varying amounts across years\n",
    "   - Primary loss values are indeed smaller than total tree cover loss values, as expected\n",
    "   - The large standard deviations indicate significant variation across countries\n",
    "\n",
    "5. **Missing Values:**\n",
    "   - **No missing values found** in the dataset (excellent data quality!)\n",
    "   - However, the dataset only includes 76 countries (vs. many more in tree cover loss), suggesting countries without primary forests are simply not included\n",
    "   - Zero values in year columns likely represent \"no primary forest loss\" rather than missing data\n",
    "\n",
    "6. **Geographic and Temporal Coverage:**\n",
    "   - **76 unique countries** represented (significantly fewer than tree cover loss's 1,328 rows, which includes multiple thresholds per country)\n",
    "   - Countries include major primary forest nations: Brazil, Indonesia, Democratic Republic of the Congo, Peru, Colombia, etc.\n",
    "   - **Threshold values**: Only threshold 30 (single value, unlike tree cover loss)\n",
    "   - **Year range**: 2002 to 2024 (23 years of data, missing 2001)\n",
    "   - **Year columns**: 23 columns found\n",
    "\n",
    "7. **Relationship to Tree Cover Loss:**\n",
    "   - This dataset uses the same country identifiers as tree cover loss, but **only includes threshold 30**\n",
    "   - Can be merged with tree cover loss data on country, threshold (30), and year\n",
    "   - **Important validation**: Primary loss values should be \u2264 tree cover loss values for the same country/year/threshold 30\n",
    "   - Primary forests are a subset of total forests, so primary loss should never exceed total loss\n",
    "   - **Column name difference**: `area__ha` (double underscore) vs. `area_ha` in tree cover loss - will need standardization\n",
    "\n",
    "**Implication for Data Preparation:**\n",
    "- This sheet will need the same wide-to-long format transformation as tree cover loss\n",
    "- **Important**: Year extraction must account for starting year 2002 (not 2001)\n",
    "- Can be merged with tree cover loss after reshaping using country + threshold (30) + year as keys\n",
    "- Should implement validation to ensure primary loss \u2264 total loss during data preparation\n",
    "- Column name `area__ha` needs to be standardized to `area_ha` for consistency\n",
    "- After reshaping, we expect approximately 76 \u00d7 23 = ~1,748 rows (if all years have data)\n",
    "- The smaller dataset size (76 countries vs. many more in tree cover loss) means we'll need to decide on merge strategy (inner vs. outer join)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16b643aa75800c1",
   "metadata": {},
   "source": [
    "### 1.3 Sheet 3: Country Drivers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb843ce",
   "metadata": {},
   "source": [
    "## Step 3: Exploring Country Drivers Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8331ab1596ea784",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T14:17:53.851084Z",
     "start_time": "2025-11-29T14:17:52.768166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COUNTRY DRIVERS - RAW DATA\n",
      "================================================================================\n",
      "Shape: 21,897 rows \u00d7 5 columns\n",
      "\n",
      "Column names (5):\n",
      "   1. country\n",
      "   2. threshold\n",
      "   3. driver\n",
      "   4. year\n",
      "   5. tc_loss_ha\n",
      "\n",
      "================================================================================\n",
      "First 5 rows:\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>threshold</th>\n",
       "      <th>driver</th>\n",
       "      <th>year</th>\n",
       "      <th>tc_loss_ha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>30</td>\n",
       "      <td>Hard commodities</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>30</td>\n",
       "      <td>Logging</td>\n",
       "      <td>2001</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>30</td>\n",
       "      <td>Logging</td>\n",
       "      <td>2002</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>30</td>\n",
       "      <td>Logging</td>\n",
       "      <td>2003</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>30</td>\n",
       "      <td>Logging</td>\n",
       "      <td>2004</td>\n",
       "      <td>143.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  threshold            driver  year  tc_loss_ha\n",
       "0  Afghanistan         30  Hard commodities  2014         0.0\n",
       "1  Afghanistan         30           Logging  2001         3.0\n",
       "2  Afghanistan         30           Logging  2002        64.0\n",
       "3  Afghanistan         30           Logging  2003        73.0\n",
       "4  Afghanistan         30           Logging  2004       143.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Driver type columns: ['driver', 'year', 'tc_loss_ha']\n",
      "Year-based columns: 0\n",
      "\n",
      "================================================================================\n",
      "Missing Values:\n",
      "================================================================================\n",
      "\u2705 No missing values!\n"
     ]
    }
   ],
   "source": [
    "df_drivers = excel_file.parse(\"Country drivers\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"COUNTRY DRIVERS - RAW DATA\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Shape: {df_drivers.shape[0]:,} rows \u00d7 {df_drivers.shape[1]} columns\")\n",
    "print(f\"\\nColumn names ({len(df_drivers.columns)}):\")\n",
    "for i, col in enumerate(df_drivers.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"First 5 rows:\")\n",
    "print(\"=\"*80)\n",
    "display(df_drivers.head())\n",
    "\n",
    "driver_type_cols = [c for c in df_drivers.columns if c not in ['country', 'threshold'] and not any(str(year) in c for year in range(2001, 2025))]\n",
    "print(f\"\\nDriver type columns: {driver_type_cols}\")\n",
    "\n",
    "year_cols = [col for col in df_drivers.columns if any(str(year) in col for year in range(2001, 2025))]\n",
    "print(f\"Year-based columns: {len(year_cols)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Missing Values:\")\n",
    "print(\"=\"*80)\n",
    "missing = df_drivers.isnull().sum()\n",
    "if missing.sum() > 0:\n",
    "    display(pd.DataFrame({'Missing Count': missing[missing > 0]}))\n",
    "else:\n",
    "    print(\"\u2705 No missing values!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c37e0948391822f",
   "metadata": {},
   "source": [
    "**Findings:**\n",
    "\n",
    "From exploring the Country Drivers sheet, we discovered:\n",
    "\n",
    "1. **Data Structure:**\n",
    "   - The sheet contains **21,897 rows and 5 columns**\n",
    "   - **Critical difference**: The data is already in **LONG format** (unlike tree cover loss and primary loss which are in wide format)\n",
    "   - This is a significant advantage as it doesn't require reshaping during data preparation\n",
    "   - The structure is: one row per country-threshold-driver-year combination\n",
    "\n",
    "2. **Key Columns Identified:**\n",
    "   - `country`: Country names (object/string type)\n",
    "   - `threshold`: Canopy density threshold values (int64 type)\n",
    "   - `driver`: Driver category names (object/string type) - represents the cause of deforestation\n",
    "   - `year`: Year values (int64 type) - already extracted as a column (not in column names)\n",
    "   - `tc_loss_ha`: Tree cover loss in hectares attributed to that specific driver (float64 type)\n",
    "\n",
    "3. **Driver Categories:**\n",
    "   - The `driver` column contains categorical values representing different causes of deforestation\n",
    "   - Examples from the data: \"Hard commodities\", \"Logging\"\n",
    "   - These represent the main causes of deforestation tracked by Global Forest Watch\n",
    "   - Each row represents loss attributed to a specific driver for a specific country-threshold-year combination\n",
    "\n",
    "4. **Data Types:**\n",
    "   - Country and driver names are stored as **object** (strings)\n",
    "   - Threshold and year are stored as **int64** (integers)\n",
    "   - Loss values are stored as **float64** (floats), which allows for precise measurements\n",
    "   - All data types are appropriate for the data content\n",
    "\n",
    "5. **Data Completeness:**\n",
    "   - **No missing values found** in the dataset (excellent data quality!)\n",
    "   - **21,897 rows** represent multiple driver types per country-threshold-year combination\n",
    "   - The large number of rows (compared to other sheets) reflects the long format structure\n",
    "\n",
    "6. **Important Structural Difference:**\n",
    "   - **Unlike tree cover loss and primary loss sheets**, this data is already in long format\n",
    "   - No year-based columns (0 year-based columns found)\n",
    "   - Year is already a separate column, making this dataset ready for merging without reshaping\n",
    "   - This suggests the data was pre-processed differently than the loss datasets\n",
    "\n",
    "7. **Relationship to Other Sheets:**\n",
    "   - Can be merged with tree cover loss data using: country + threshold + year as keys\n",
    "   - After merging, we can analyze which drivers contribute most to forest loss\n",
    "   - Driver values represent a breakdown of total loss by cause, so summing drivers for a country-threshold-year should approximate (but may not exactly equal) total loss\n",
    "   - Some loss may be unclassified or attributed to multiple causes\n",
    "\n",
    "**Implication for Data Preparation:**\n",
    "- **No reshaping needed** - this sheet is already in the desired long format\n",
    "- Can be directly merged with reshaped loss data using country + threshold + year as merge keys\n",
    "- May want to pivot driver column to create separate columns for each driver type (e.g., `hard_commodities_ha`, `logging_ha`) for easier analysis, or keep in long format depending on analysis needs\n",
    "- The float64 data type for `tc_loss_ha` is appropriate for precise measurements\n",
    "- This dataset will be easier to integrate than the loss datasets since it doesn't require wide-to-long transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb20f49310de566",
   "metadata": {},
   "source": [
    "### 1.4 Sheet 4: Country Carbon Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cea8be",
   "metadata": {},
   "source": [
    "## Step 4: Exploring Country Carbon Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cbaabe34b40d3ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T13:55:42.814057Z",
     "start_time": "2025-11-29T13:55:42.576394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COUNTRY CARBON DATA - RAW DATA\n",
      "================================================================================\n",
      "Shape: 498 rows \u00d7 32 columns\n",
      "\n",
      "Column names (32):\n",
      "   1. country\n",
      "   2. umd_tree_cover_density_2000__threshold\n",
      "   3. umd_tree_cover_extent_2000__ha\n",
      "   4. gfw_aboveground_carbon_stocks_2000__Mg_C\n",
      "   5. avg_gfw_aboveground_carbon_stocks_2000__Mg_C_ha-1\n",
      "   6. gfw_forest_carbon_gross_emissions__Mg_CO2e_yr-1\n",
      "   7. gfw_forest_carbon_gross_removals__Mg_CO2_yr-1\n",
      "   8. gfw_forest_carbon_net_flux__Mg_CO2e_yr-1\n",
      "   9. gfw_forest_carbon_gross_emissions_2001__Mg_CO2e\n",
      "  10. gfw_forest_carbon_gross_emissions_2002__Mg_CO2e\n",
      "  11. gfw_forest_carbon_gross_emissions_2003__Mg_CO2e\n",
      "  12. gfw_forest_carbon_gross_emissions_2004__Mg_CO2e\n",
      "  13. gfw_forest_carbon_gross_emissions_2005__Mg_CO2e\n",
      "  14. gfw_forest_carbon_gross_emissions_2006__Mg_CO2e\n",
      "  15. gfw_forest_carbon_gross_emissions_2007__Mg_CO2e\n",
      "  16. gfw_forest_carbon_gross_emissions_2008__Mg_CO2e\n",
      "  17. gfw_forest_carbon_gross_emissions_2009__Mg_CO2e\n",
      "  18. gfw_forest_carbon_gross_emissions_2010__Mg_CO2e\n",
      "  19. gfw_forest_carbon_gross_emissions_2011__Mg_CO2e\n",
      "  20. gfw_forest_carbon_gross_emissions_2012__Mg_CO2e\n",
      "  21. gfw_forest_carbon_gross_emissions_2013__Mg_CO2e\n",
      "  22. gfw_forest_carbon_gross_emissions_2014__Mg_CO2e\n",
      "  23. gfw_forest_carbon_gross_emissions_2015__Mg_CO2e\n",
      "  24. gfw_forest_carbon_gross_emissions_2016__Mg_CO2e\n",
      "  25. gfw_forest_carbon_gross_emissions_2017__Mg_CO2e\n",
      "  26. gfw_forest_carbon_gross_emissions_2018__Mg_CO2e\n",
      "  27. gfw_forest_carbon_gross_emissions_2019__Mg_CO2e\n",
      "  28. gfw_forest_carbon_gross_emissions_2020__Mg_CO2e\n",
      "  29. gfw_forest_carbon_gross_emissions_2021__Mg_CO2e\n",
      "  30. gfw_forest_carbon_gross_emissions_2022__Mg_CO2e\n",
      "  31. gfw_forest_carbon_gross_emissions_2023__Mg_CO2e\n",
      "  32. gfw_forest_carbon_gross_emissions_2024__Mg_CO2e\n",
      "\n",
      "================================================================================\n",
      "First 5 rows:\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>umd_tree_cover_density_2000__threshold</th>\n",
       "      <th>umd_tree_cover_extent_2000__ha</th>\n",
       "      <th>gfw_aboveground_carbon_stocks_2000__Mg_C</th>\n",
       "      <th>avg_gfw_aboveground_carbon_stocks_2000__Mg_C_ha-1</th>\n",
       "      <th>gfw_forest_carbon_gross_emissions__Mg_CO2e_yr-1</th>\n",
       "      <th>gfw_forest_carbon_gross_removals__Mg_CO2_yr-1</th>\n",
       "      <th>gfw_forest_carbon_net_flux__Mg_CO2e_yr-1</th>\n",
       "      <th>gfw_forest_carbon_gross_emissions_2001__Mg_CO2e</th>\n",
       "      <th>gfw_forest_carbon_gross_emissions_2002__Mg_CO2e</th>\n",
       "      <th>...</th>\n",
       "      <th>gfw_forest_carbon_gross_emissions_2015__Mg_CO2e</th>\n",
       "      <th>gfw_forest_carbon_gross_emissions_2016__Mg_CO2e</th>\n",
       "      <th>gfw_forest_carbon_gross_emissions_2017__Mg_CO2e</th>\n",
       "      <th>gfw_forest_carbon_gross_emissions_2018__Mg_CO2e</th>\n",
       "      <th>gfw_forest_carbon_gross_emissions_2019__Mg_CO2e</th>\n",
       "      <th>gfw_forest_carbon_gross_emissions_2020__Mg_CO2e</th>\n",
       "      <th>gfw_forest_carbon_gross_emissions_2021__Mg_CO2e</th>\n",
       "      <th>gfw_forest_carbon_gross_emissions_2022__Mg_CO2e</th>\n",
       "      <th>gfw_forest_carbon_gross_emissions_2023__Mg_CO2e</th>\n",
       "      <th>gfw_forest_carbon_gross_emissions_2024__Mg_CO2e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>30</td>\n",
       "      <td>205771</td>\n",
       "      <td>12409398</td>\n",
       "      <td>123</td>\n",
       "      <td>15339</td>\n",
       "      <td>376800</td>\n",
       "      <td>-361461</td>\n",
       "      <td>27986.0</td>\n",
       "      <td>41762.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4893.0</td>\n",
       "      <td>3708.0</td>\n",
       "      <td>11409.0</td>\n",
       "      <td>6772.0</td>\n",
       "      <td>1913.0</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>2636.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>50</td>\n",
       "      <td>148417</td>\n",
       "      <td>9765465</td>\n",
       "      <td>134</td>\n",
       "      <td>12657</td>\n",
       "      <td>275855</td>\n",
       "      <td>-263199</td>\n",
       "      <td>25603.0</td>\n",
       "      <td>32691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3920.0</td>\n",
       "      <td>3343.0</td>\n",
       "      <td>10321.0</td>\n",
       "      <td>6045.0</td>\n",
       "      <td>1664.0</td>\n",
       "      <td>2530.0</td>\n",
       "      <td>2106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>75</td>\n",
       "      <td>75480</td>\n",
       "      <td>5571655</td>\n",
       "      <td>150</td>\n",
       "      <td>6147</td>\n",
       "      <td>151074</td>\n",
       "      <td>-144926</td>\n",
       "      <td>15780.0</td>\n",
       "      <td>15308.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>1743.0</td>\n",
       "      <td>6451.0</td>\n",
       "      <td>2477.0</td>\n",
       "      <td>668.0</td>\n",
       "      <td>1857.0</td>\n",
       "      <td>1512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>30</td>\n",
       "      <td>648459</td>\n",
       "      <td>40958831</td>\n",
       "      <td>238</td>\n",
       "      <td>721806</td>\n",
       "      <td>5103589</td>\n",
       "      <td>-4381783</td>\n",
       "      <td>1417747.0</td>\n",
       "      <td>348556.0</td>\n",
       "      <td>...</td>\n",
       "      <td>120041.0</td>\n",
       "      <td>334094.0</td>\n",
       "      <td>448993.0</td>\n",
       "      <td>724335.0</td>\n",
       "      <td>429556.0</td>\n",
       "      <td>427420.0</td>\n",
       "      <td>506228.0</td>\n",
       "      <td>649874.0</td>\n",
       "      <td>948758.0</td>\n",
       "      <td>308121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albania</td>\n",
       "      <td>50</td>\n",
       "      <td>534671</td>\n",
       "      <td>37239867</td>\n",
       "      <td>263</td>\n",
       "      <td>682919</td>\n",
       "      <td>4294627</td>\n",
       "      <td>-3611709</td>\n",
       "      <td>1358272.0</td>\n",
       "      <td>338279.0</td>\n",
       "      <td>...</td>\n",
       "      <td>113553.0</td>\n",
       "      <td>304691.0</td>\n",
       "      <td>403366.0</td>\n",
       "      <td>669011.0</td>\n",
       "      <td>404887.0</td>\n",
       "      <td>391385.0</td>\n",
       "      <td>449937.0</td>\n",
       "      <td>591504.0</td>\n",
       "      <td>895138.0</td>\n",
       "      <td>275104.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows \u00d7 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  umd_tree_cover_density_2000__threshold  \\\n",
       "0  Afghanistan                                      30   \n",
       "1  Afghanistan                                      50   \n",
       "2  Afghanistan                                      75   \n",
       "3      Albania                                      30   \n",
       "4      Albania                                      50   \n",
       "\n",
       "   umd_tree_cover_extent_2000__ha  gfw_aboveground_carbon_stocks_2000__Mg_C  \\\n",
       "0                          205771                                  12409398   \n",
       "1                          148417                                   9765465   \n",
       "2                           75480                                   5571655   \n",
       "3                          648459                                  40958831   \n",
       "4                          534671                                  37239867   \n",
       "\n",
       "   avg_gfw_aboveground_carbon_stocks_2000__Mg_C_ha-1  \\\n",
       "0                                                123   \n",
       "1                                                134   \n",
       "2                                                150   \n",
       "3                                                238   \n",
       "4                                                263   \n",
       "\n",
       "   gfw_forest_carbon_gross_emissions__Mg_CO2e_yr-1  \\\n",
       "0                                            15339   \n",
       "1                                            12657   \n",
       "2                                             6147   \n",
       "3                                           721806   \n",
       "4                                           682919   \n",
       "\n",
       "   gfw_forest_carbon_gross_removals__Mg_CO2_yr-1  \\\n",
       "0                                         376800   \n",
       "1                                         275855   \n",
       "2                                         151074   \n",
       "3                                        5103589   \n",
       "4                                        4294627   \n",
       "\n",
       "   gfw_forest_carbon_net_flux__Mg_CO2e_yr-1  \\\n",
       "0                                   -361461   \n",
       "1                                   -263199   \n",
       "2                                   -144926   \n",
       "3                                  -4381783   \n",
       "4                                  -3611709   \n",
       "\n",
       "   gfw_forest_carbon_gross_emissions_2001__Mg_CO2e  \\\n",
       "0                                          27986.0   \n",
       "1                                          25603.0   \n",
       "2                                          15780.0   \n",
       "3                                        1417747.0   \n",
       "4                                        1358272.0   \n",
       "\n",
       "   gfw_forest_carbon_gross_emissions_2002__Mg_CO2e  ...  \\\n",
       "0                                          41762.0  ...   \n",
       "1                                          32691.0  ...   \n",
       "2                                          15308.0  ...   \n",
       "3                                         348556.0  ...   \n",
       "4                                         338279.0  ...   \n",
       "\n",
       "   gfw_forest_carbon_gross_emissions_2015__Mg_CO2e  \\\n",
       "0                                              0.0   \n",
       "1                                              0.0   \n",
       "2                                              0.0   \n",
       "3                                         120041.0   \n",
       "4                                         113553.0   \n",
       "\n",
       "   gfw_forest_carbon_gross_emissions_2016__Mg_CO2e  \\\n",
       "0                                              0.0   \n",
       "1                                              0.0   \n",
       "2                                              0.0   \n",
       "3                                         334094.0   \n",
       "4                                         304691.0   \n",
       "\n",
       "   gfw_forest_carbon_gross_emissions_2017__Mg_CO2e  \\\n",
       "0                                              0.0   \n",
       "1                                              0.0   \n",
       "2                                              0.0   \n",
       "3                                         448993.0   \n",
       "4                                         403366.0   \n",
       "\n",
       "   gfw_forest_carbon_gross_emissions_2018__Mg_CO2e  \\\n",
       "0                                           4893.0   \n",
       "1                                           3920.0   \n",
       "2                                           1962.0   \n",
       "3                                         724335.0   \n",
       "4                                         669011.0   \n",
       "\n",
       "   gfw_forest_carbon_gross_emissions_2019__Mg_CO2e  \\\n",
       "0                                           3708.0   \n",
       "1                                           3343.0   \n",
       "2                                           1743.0   \n",
       "3                                         429556.0   \n",
       "4                                         404887.0   \n",
       "\n",
       "   gfw_forest_carbon_gross_emissions_2020__Mg_CO2e  \\\n",
       "0                                          11409.0   \n",
       "1                                          10321.0   \n",
       "2                                           6451.0   \n",
       "3                                         427420.0   \n",
       "4                                         391385.0   \n",
       "\n",
       "   gfw_forest_carbon_gross_emissions_2021__Mg_CO2e  \\\n",
       "0                                           6772.0   \n",
       "1                                           6045.0   \n",
       "2                                           2477.0   \n",
       "3                                         506228.0   \n",
       "4                                         449937.0   \n",
       "\n",
       "   gfw_forest_carbon_gross_emissions_2022__Mg_CO2e  \\\n",
       "0                                           1913.0   \n",
       "1                                           1664.0   \n",
       "2                                            668.0   \n",
       "3                                         649874.0   \n",
       "4                                         591504.0   \n",
       "\n",
       "   gfw_forest_carbon_gross_emissions_2023__Mg_CO2e  \\\n",
       "0                                           3435.0   \n",
       "1                                           2530.0   \n",
       "2                                           1857.0   \n",
       "3                                         948758.0   \n",
       "4                                         895138.0   \n",
       "\n",
       "   gfw_forest_carbon_gross_emissions_2024__Mg_CO2e  \n",
       "0                                           2636.0  \n",
       "1                                           2106.0  \n",
       "2                                           1512.0  \n",
       "3                                         308121.0  \n",
       "4                                         275104.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Missing Values:\n",
      "================================================================================\n",
      "\u2705 No missing values!\n",
      "\n",
      "Carbon-related columns: ['gfw_aboveground_carbon_stocks_2000__Mg_C', 'avg_gfw_aboveground_carbon_stocks_2000__Mg_C_ha-1', 'gfw_forest_carbon_gross_emissions__Mg_CO2e_yr-1', 'gfw_forest_carbon_gross_removals__Mg_CO2_yr-1', 'gfw_forest_carbon_net_flux__Mg_CO2e_yr-1', 'gfw_forest_carbon_gross_emissions_2001__Mg_CO2e', 'gfw_forest_carbon_gross_emissions_2002__Mg_CO2e', 'gfw_forest_carbon_gross_emissions_2003__Mg_CO2e', 'gfw_forest_carbon_gross_emissions_2004__Mg_CO2e', 'gfw_forest_carbon_gross_emissions_2005__Mg_CO2e', 'gfw_forest_carbon_gross_emissions_2006__Mg_CO2e', 'gfw_forest_carbon_gross_emissions_2007__Mg_CO2e', 'gfw_forest_carbon_gross_emissions_2008__Mg_CO2e', 'gfw_forest_carbon_gross_emissions_2009__Mg_CO2e', 'gfw_forest_carbon_gross_emissions_2010__Mg_CO2e', 'gfw_forest_carbon_gross_emissions_2011__Mg_CO2e', 'gfw_forest_carbon_gross_emissions_2012__Mg_CO2e', 'gfw_forest_carbon_gross_emissions_2013__Mg_CO2e', 'gfw_forest_carbon_gross_emissions_2014__Mg_CO2e', 'gfw_forest_carbon_gross_emissions_2015__Mg_CO2e', 'gfw_forest_carbon_gross_emissions_2016__Mg_CO2e', 'gfw_forest_carbon_gross_emissions_2017__Mg_CO2e', 'gfw_forest_carbon_gross_emissions_2018__Mg_CO2e', 'gfw_forest_carbon_gross_emissions_2019__Mg_CO2e', 'gfw_forest_carbon_gross_emissions_2020__Mg_CO2e', 'gfw_forest_carbon_gross_emissions_2021__Mg_CO2e', 'gfw_forest_carbon_gross_emissions_2022__Mg_CO2e', 'gfw_forest_carbon_gross_emissions_2023__Mg_CO2e', 'gfw_forest_carbon_gross_emissions_2024__Mg_CO2e']\n"
     ]
    }
   ],
   "source": [
    "df_carbon = excel_file.parse(\"Country carbon data\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"COUNTRY CARBON DATA - RAW DATA\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Shape: {df_carbon.shape[0]:,} rows \u00d7 {df_carbon.shape[1]} columns\")\n",
    "print(f\"\\nColumn names ({len(df_carbon.columns)}):\")\n",
    "for i, col in enumerate(df_carbon.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"First 5 rows:\")\n",
    "print(\"=\"*80)\n",
    "display(df_carbon.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Missing Values:\")\n",
    "print(\"=\"*80)\n",
    "missing = df_carbon.isnull().sum()\n",
    "if missing.sum() > 0:\n",
    "    display(pd.DataFrame({'Missing Count': missing[missing > 0]}))\n",
    "else:\n",
    "    print(\"\u2705 No missing values!\")\n",
    "\n",
    "carbon_metric_cols = [c for c in df_carbon.columns if 'carbon' in c.lower() or 'emission' in c.lower()]\n",
    "print(f\"\\nCarbon-related columns: {carbon_metric_cols}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93328da09cc827a9",
   "metadata": {},
   "source": [
    "**Findings:**\n",
    "\n",
    "From exploring the Country Carbon Data sheet, we discovered:\n",
    "\n",
    "1. **Data Structure:**\n",
    "   - The sheet contains **498 rows and 32 columns**\n",
    "   - The data is in **wide format** with separate columns for each year (`gfw_forest_carbon_gross_emissions_2001__Mg_CO2e` through `gfw_forest_carbon_gross_emissions_2024__Mg_CO2e`)\n",
    "   - This represents 24 years of annual emissions data (2001-2024) plus 8 metadata columns\n",
    "   - The wide format will need to be converted to long format during data preparation\n",
    "   - Similar structure to tree cover loss and primary loss sheets\n",
    "\n",
    "2. **Key Columns Identified:**\n",
    "   - `country`: Country names (object/string type)\n",
    "   - `umd_tree_cover_density_2000__threshold`: Canopy density threshold values (int64 type) - **Note**: Column name differs from other sheets (uses `umd_tree_cover_density_2000__threshold` instead of `threshold`)\n",
    "   - `umd_tree_cover_extent_2000__ha`: Tree cover extent in year 2000 (int64)\n",
    "   - `gfw_aboveground_carbon_stocks_2000__Mg_C`: Total carbon stored in forests in 2000 (int64)\n",
    "   - `avg_gfw_aboveground_carbon_stocks_2000__Mg_C_ha-1`: Average carbon density per hectare in 2000 (int64)\n",
    "   - `gfw_forest_carbon_gross_emissions__Mg_CO2e_yr-1`: Annual gross carbon emissions (int64)\n",
    "   - `gfw_forest_carbon_gross_removals__Mg_CO2_yr-1`: Annual gross carbon removals (int64)\n",
    "   - `gfw_forest_carbon_net_flux__Mg_CO2e_yr-1`: Net carbon flux (emissions - removals) (int64)\n",
    "   - **24 year-based columns**: `gfw_forest_carbon_gross_emissions_2001__Mg_CO2e` through `gfw_forest_carbon_gross_emissions_2024__Mg_CO2e` representing annual carbon emissions\n",
    "\n",
    "3. **Carbon Metrics Available:**\n",
    "   - **Carbon Stocks (2000 baseline)**: `gfw_aboveground_carbon_stocks_2000__Mg_C` - Total carbon stored in forests\n",
    "   - **Average Carbon Density**: `avg_gfw_aboveground_carbon_stocks_2000__Mg_C_ha-1` - Carbon per hectare\n",
    "   - **Annual Gross Emissions**: `gfw_forest_carbon_gross_emissions__Mg_CO2e_yr-1` - Total annual emissions\n",
    "   - **Annual Gross Removals**: `gfw_forest_carbon_gross_removals__Mg_CO2_yr-1` - Total annual removals\n",
    "   - **Net Carbon Flux**: `gfw_forest_carbon_net_flux__Mg_CO2e_yr-1` - Net change (emissions - removals)\n",
    "   - **Yearly Emissions (2001-2024)**: 24 columns with annual emissions data\n",
    "\n",
    "4. **Data Types:**\n",
    "   - Most numeric columns are stored as **int64** (integers)\n",
    "   - Year-based emission columns are stored as **float64** (floats), allowing for precise measurements\n",
    "   - Country names are stored as **object** (strings)\n",
    "   - Data types are appropriate for the data content\n",
    "\n",
    "5. **Units:**\n",
    "   - Carbon stocks: **Mg C** (Megagrams of Carbon)\n",
    "   - Carbon emissions: **Mg CO2e** (Megagrams of CO2 equivalent)\n",
    "   - Carbon removals: **Mg CO2** (Megagrams of CO2)\n",
    "   - Tree cover extent: **ha** (hectares)\n",
    "   - **Important**: Units must be preserved and documented during merging\n",
    "\n",
    "6. **Data Quality:**\n",
    "   - **No missing values found** in the dataset (excellent data quality!)\n",
    "   - **498 rows** represent country-threshold combinations (similar to tree cover loss structure)\n",
    "   - The dataset includes multiple threshold values per country\n",
    "\n",
    "7. **Relationship to Other Sheets:**\n",
    "   - Can be merged with tree cover loss data using: country + threshold + year as keys\n",
    "   - **Important**: The threshold column name differs (`umd_tree_cover_density_2000__threshold` vs. `threshold`) - will need standardization during data preparation\n",
    "   - Carbon emissions can be linked to forest loss to quantify climate impact\n",
    "   - The year-based emission columns (2001-2024) align with the loss data time period\n",
    "\n",
    "8. **Temporal Coverage:**\n",
    "   - **Year range**: 2001 to 2024 (24 years of data)\n",
    "   - Baseline year: 2000 (for carbon stocks and tree cover extent)\n",
    "   - Annual emissions data available for each year in the range\n",
    "\n",
    "**Implication for Data Preparation:**\n",
    "- This sheet will need the same wide-to-long format transformation as tree cover loss and primary loss\n",
    "- Year extraction must account for starting year 2001 (same as tree cover loss)\n",
    "- **Column name standardization needed**: `umd_tree_cover_density_2000__threshold` should be renamed to `threshold` for consistency with other sheets\n",
    "- Can be merged with loss data after reshaping using country + threshold + year as keys\n",
    "- After reshaping, we expect approximately 498 \u00d7 24 = ~11,952 rows (if all years have data)\n",
    "- Units must be preserved and clearly documented in the final merged dataset\n",
    "- The carbon data enables climate impact analysis by linking deforestation to carbon emissions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bded6a9bbc2062c8",
   "metadata": {},
   "source": [
    "**Final Summary: CRISP-DM Data Understanding Phase Completion**\n",
    "\n",
    "This notebook represents the completion of the **Data Understanding** phase of the CRISP-DM methodology. Through systematic exploration of the raw Global Forest Watch data, we have achieved the key objectives of this phase:\n",
    "\n",
    "1. **Data Collection and Initial Assessment:**\n",
    "   - Successfully loaded and cataloged all available data sources (9 sheets total)\n",
    "   - Identified and focused on the four country-level datasets relevant to our analysis\n",
    "   - Documented the data source structure and organization\n",
    "\n",
    "2. **Data Description:**\n",
    "   - Characterized the structure of each dataset (wide format with year-based columns for loss and carbon data; long format for drivers data)\n",
    "   - Documented all column names, data types, and basic statistics for each sheet\n",
    "   - Identified 1,328 rows in tree cover loss, 76 rows in primary loss, 21,897 rows in drivers, and 498 rows in carbon data\n",
    "\n",
    "3. **Data Quality Assessment:**\n",
    "   - Evaluated missing values across all sheets (found no missing values in any dataset - excellent quality!)\n",
    "   - Identified data inconsistencies (e.g., different threshold column names, different starting years)\n",
    "   - Assessed data completeness and coverage (166 countries in tree cover loss, 76 in primary loss, 158 in drivers, 166 in carbon data)\n",
    "\n",
    "4. **Data Exploration:**\n",
    "   - Examined relationships between datasets (common identifiers: country, threshold, year)\n",
    "   - Identified 76 countries present in all sheets (critical for merging strategy)\n",
    "   - Discovered structural differences (drivers data already in long format; others need reshaping)\n",
    "\n",
    "5. **Documentation of Findings:**\n",
    "   - Created comprehensive documentation of data characteristics\n",
    "   - Identified specific data preparation requirements (reshaping, column standardization, merge strategy)\n",
    "   - Established clear expectations for the next phase\n",
    "\n",
    "**Transition to Data Preparation Phase (CRISP-DM):**\n",
    "\n",
    "The findings from this Data Understanding phase directly inform the **Data Preparation** phase (02_data_preparation.ipynb), where we will:\n",
    "\n",
    "- **Data Selection:** Focus on the four country-level datasets identified\n",
    "- **Data Cleaning:** Standardize column names (e.g., `umd_tree_cover_density_2000__threshold` \u2192 `threshold`, `area__ha` \u2192 `area_ha`)\n",
    "- **Data Construction:** Reshape wide format to long format for tree cover loss, primary loss, and carbon data\n",
    "- **Data Integration:** Merge all sheets using country + threshold + year as keys\n",
    "- **Data Formatting:** Ensure consistent data types and units across the merged dataset\n",
    "\n",
    "This systematic Data Understanding phase ensures that our Data Preparation phase will be:\n",
    "- **Informed:** Based on actual data characteristics, not assumptions\n",
    "- **Efficient:** Addressing only real issues identified through exploration\n",
    "- **Comprehensive:** Covering all identified data quality and structural concerns\n",
    "- **Aligned with CRISP-DM:** Following the methodology's structured approach to data science projects\n",
    "\n",
    "The completion of this phase provides a solid foundation for the subsequent phases of CRISP-DM: Data Preparation, Modeling, Evaluation, and Deployment.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}